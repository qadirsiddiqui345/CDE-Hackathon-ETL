{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9623a19d-ea39-4bfe-8e53-7f7c4af71ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploratory_analysis.py (Revised for Stock Analysis)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set up visualization styles\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "def analyze_price_distribution(df: pd.DataFrame):\n",
    "    \"\"\"Analysis 1: Price Distribution per Category using Box Plots.\"\"\"\n",
    "    print(\"\\n--- 1. Price Distribution per Category ---\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='Category', y='Price_Clean', data=df)\n",
    "    plt.title('Product Price Distribution by Category')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Cleaned Price (USD)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    print(\"Insight: Box plots effectively summarize the median, spread, and outliers of product prices in each category.\")\n",
    "\n",
    "\n",
    "def analyze_rating_price_correlation(df: pd.DataFrame):\n",
    "    \"\"\"Analysis 2: Correlation between Rating and Price.\"\"\"\n",
    "    print(\"\\n--- 2. Correlation between Rating and Price ---\")\n",
    "\n",
    "    correlation = df['Price_Clean'].corr(df['Rating'])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='Price_Clean', y='Rating', data=df, alpha=0.6)\n",
    "    plt.title(f'Rating vs. Price (Correlation: {correlation:.2f})')\n",
    "    plt.xlabel('Cleaned Price (USD)')\n",
    "    plt.ylabel('Rating')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"Insight: The correlation coefficient is {correlation:.2f}. Indicates the strength and direction of the linear relationship between price and rating.\")\n",
    "\n",
    "\n",
    "def analyze_top_reviewed_products(df: pd.DataFrame):\n",
    "    \"\"\"Analysis 3: Top Reviewed Products.\"\"\"\n",
    "    print(\"\\n--- 3. Top Reviewed Products ---\")\n",
    "\n",
    "    reviewed_products = df[df['Reviews'] > 0]\n",
    "\n",
    "    if not reviewed_products.empty:\n",
    "        top_reviewed = reviewed_products.sort_values(by='Reviews', ascending=False).head(10)\n",
    "        \n",
    "        print(\"\\nTop 10 Products by Review Count:\")\n",
    "        print(top_reviewed[['Name', 'Category', 'Reviews', 'Rating']])\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x='Reviews', y='Name', data=top_reviewed, palette='viridis')\n",
    "        plt.title('Top 10 Products by Total Reviews')\n",
    "        plt.xlabel('Total Reviews')\n",
    "        plt.ylabel('Product Name')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Insight: Cannot visualize top reviews as the 'Reviews' column is currently filled with placeholders (0).\")\n",
    "\n",
    "\n",
    "def analyze_best_value_metric(df: pd.DataFrame):\n",
    "    \"\"\"Analysis 4: Best Value Metric (Rating-to-Price Ratio) per Category.\"\"\"\n",
    "    print(\"\\n--- 4. Best Value Metric (Rating/Price) per Category ---\")\n",
    "\n",
    "    # Calculate Value Score: Rating / Price (filter non-positive values)\n",
    "    df_value = df[(df['Price_Clean'] >= 1) & (df['Rating'] > 0)].copy()\n",
    "    if df_value.empty:\n",
    "        print(\"Insight: Cannot calculate Value Score, insufficient data with positive ratings and prices.\")\n",
    "        return\n",
    "\n",
    "    df_value['Value_Score'] = df_value['Rating'] / df_value['Price_Clean']\n",
    "    \n",
    "    # Find the top product in each category by Value Score\n",
    "    best_value_per_category = df_value.loc[df_value.groupby('Category')['Value_Score'].idxmax()]\n",
    "\n",
    "    print(\"\\nProduct with the Highest Value Score (Rating/Price) in Each Category:\")\n",
    "    print(best_value_per_category[['Category', 'Name', 'Rating', 'Price_Clean', 'Value_Score']].sort_values(by='Category'))\n",
    "    print(\"Insight: Identifies products offering high customer satisfaction relative to their cost.\")\n",
    "\n",
    "\n",
    "def analyze_simulated_stock_availability(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Analysis 5: Simulated Stock Availability based on assumed inventory trends.\n",
    "    \n",
    "    Since real stock data isn't available, we simulate a 'Low Stock Risk' score \n",
    "    based on the assumption that high reviews/demand and low price correlation \n",
    "    might lead to faster depletion.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 5. Simulated Stock Availability Analysis ---\")\n",
    "\n",
    "    # Create a simple 'Demand Proxy' based on Reviews (assuming high reviews = high demand)\n",
    "    # Note: If Reviews are all 0, this will not be useful. We'll use Price Rank as a fallback.\n",
    "    \n",
    "    # Calculate Average Price Rank per Category\n",
    "    avg_rank = df.groupby('Category')['Price_Category_Rank'].mean().sort_values(ascending=True)\n",
    "\n",
    "    # We assume categories with products that are cheaper (lower Price Rank value) \n",
    "    # tend to sell out faster/have higher volume.\n",
    "    \n",
    "    # Visualize the proxy for volume/availability risk\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=avg_rank.index, y=avg_rank.values, palette='Reds_d')\n",
    "    plt.title('Average Price Rank by Category (Proxy for Inventory Turnover)')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Average Price Rank (Lower value = Cheaper/Higher assumed volume)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCategories sorted by Average Price Rank (Lower Rank = Higher assumed turnover risk):\")\n",
    "    print(avg_rank)\n",
    "    print(\"Insight: Categories with the lowest average Price Rank likely sell cheaper products, which might imply higher volume sales and potentially faster inventory turnover risk.\")\n",
    "\n",
    "# --- End of exploratory_analysis.py ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc57b41-060e-499a-9370-c475a4b70c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 4: Loading Data to SQL Server ---\n",
      "✅ CSV file 'my_new_scrape_data_CLEANED.csv' found.\n",
      "\n",
      "Connecting to SQL Server (localhost)...\n",
      "✅ Connected successfully.\n",
      "✅ CSV Loaded and Cleaned: 91 rows found.\n",
      "\n",
      "⏳ Inserting data into table...\n",
      "\n",
      "❌ CRITICAL ERROR: Column Name Issue. The column 'Price_Category' was not found.\n",
      "   Please check your CSV file again for correct column spelling.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0821f93f-51ce-4d33-949c-a75ec5f773b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3679834875.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m...\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "data_list.append((\n",
    "    ...\n",
    "    row['Price_Category'], # <--- Yeh column CSV mein nahi mil raha\n",
    "    ...\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8de4fe-b3f4-4b9d-aff5-5c5fb3805fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 4: Loading Data to SQL Server ---\n",
      "✅ CSV file 'my_new_scrape_data_CLEANED.csv' found.\n",
      "\n",
      "Connecting to SQL Server (localhost)...\n",
      "✅ Connected successfully.\n",
      "✅ CSV Loaded and Prepared: 91 rows found.\n",
      "\n",
      "⏳ Inserting data into table...\n",
      "✅ Upload complete. 91 rows inserted.\n",
      "✅ Validation: Total rows in SQL Table = 91\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# --- Step 4: Loading Data to SQL Server ---\n",
    "print(\"--- Step 4: Loading Data to SQL Server ---\")\n",
    "\n",
    "# Database Configuration\n",
    "# ⚠️ Apne SQL Server ka Naam Zaroor Check Karein\n",
    "SERVER = 'localhost' \n",
    "DATABASE = 'Banggood_Final'\n",
    "DRIVER = 'ODBC Driver 17 for SQL Server' \n",
    "\n",
    "# Cleaned CSV file jo abhi taiyar hui hai\n",
    "input_csv = \"my_new_scrape_data_CLEANED.csv\"\n",
    "\n",
    "conn = None\n",
    "df = pd.DataFrame()\n",
    "csv_exists = False\n",
    "connection_successful = False\n",
    "\n",
    "# 1. Check CSV File\n",
    "if not os.path.exists(input_csv):\n",
    "    print(f\"❌ Error: Cleaned CSV file '{input_csv}' not found.\")\n",
    "    print(\"   Pehle cleaning script run karein.\")\n",
    "    csv_exists = False\n",
    "else:\n",
    "    print(f\"✅ CSV file '{input_csv}' found.\")\n",
    "    csv_exists = True\n",
    "\n",
    "# --- Main Process ---\n",
    "if csv_exists:\n",
    "    try:\n",
    "        # 2. Connect to Database\n",
    "        print(f\"\\nConnecting to SQL Server ({SERVER})...\")\n",
    "        conn_str = f'DRIVER={{{DRIVER}}};SERVER={SERVER};DATABASE={DATABASE};Trusted_Connection=yes;'\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        cursor = conn.cursor()\n",
    "        print(\"✅ Connected successfully.\")\n",
    "        connection_successful = True\n",
    "\n",
    "        # 3. Load Data from CSV and Prepare\n",
    "        df = pd.read_csv(input_csv)\n",
    "        \n",
    "        # Column names se extra spaces hatayein\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # Convert NaN values to None for SQL NULLs (Zaroori step)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "        print(f\"✅ CSV Loaded and Prepared: {len(df)} rows found.\")\n",
    "\n",
    "        # 4. Insert Data\n",
    "        print(\"\\n⏳ Inserting data into table...\")\n",
    "        \n",
    "        # Purana data saaf karna (Agar zaroori ho)\n",
    "        cursor.execute(\"TRUNCATE TABLE Products\")\n",
    "        \n",
    "        # SQL INSERT QUERY (SQL table columns)\n",
    "        # Note: Est_Revenue ko hum None (NULL) bhejenge.\n",
    "        query = \"\"\"\n",
    "        INSERT INTO Products (Category, Name, Price, Rating, Reviews, URL, Price_Category, Est_Revenue)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare data list (CSV column names)\n",
    "        data_list = []\n",
    "        for i, row in df.iterrows():\n",
    "            data_list.append((\n",
    "                row['Category'], \n",
    "                row['Name'], \n",
    "                row['Price_Clean'],          # CSV: Price_Clean -> SQL: Price\n",
    "                row['Rating'], \n",
    "                row['Reviews'], \n",
    "                row['URL'], \n",
    "                row['Price_Category_Rank'],  # CSV: Price_Category_Rank -> SQL: Price_Category\n",
    "                None                         # CSV mein Est_Revenue nahi hai -> SQL: NULL\n",
    "            ))\n",
    "\n",
    "        # Execute batch insert\n",
    "        cursor.executemany(query, data_list)\n",
    "        conn.commit() \n",
    "        print(f\"✅ Upload complete. {len(data_list)} rows inserted.\")\n",
    "\n",
    "        # 5. Validate\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM Products\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(f\"✅ Validation: Total rows in SQL Table = {count}\")\n",
    "\n",
    "        conn.close() \n",
    "        print(\"Database connection closed.\")\n",
    "        \n",
    "    except pyodbc.Error as ex:\n",
    "        # Connection ya SQL error hone par\n",
    "        print(f\"\\n❌ SQL Connection or Insertion Error: {ex.args[1]}\")\n",
    "        if conn: conn.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Koi aur galti hone par\n",
    "        print(f\"\\n❌ General Error during process: {e}\")\n",
    "        if conn: conn.close()\n",
    "            \n",
    "else:\n",
    "    print(\"\\n⚠️ Process halted because CSV file was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55260eed-2b79-473e-84d0-db1db0dc16e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
